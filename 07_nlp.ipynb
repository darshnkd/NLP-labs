{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO36zTnCTJMIkiysivOLazv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darshnkd/NLP-labs/blob/main/07_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Name : Darshan Dhanwade**\n",
        "\n",
        "**Roll No : 24**"
      ],
      "metadata": {
        "id": "6r4ZMUBzHEmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical :07\n",
        "\n",
        "**AIM :** Perform ngram on corpus in NLP.\n"
      ],
      "metadata": {
        "id": "2Lvr0vEMHWFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import bigrams, trigrams\n",
        "from nltk import ngrams"
      ],
      "metadata": {
        "id": "_pyiwTxoHQqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Language modeling is the way of determining the probability of any sequence of words.\""
      ],
      "metadata": {
        "id": "tAqyRYAPX9rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform the trigrams\n",
        "text_trigrams = list(trigrams(text.split()))\n",
        "text_trigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5EqrsLeJD5M",
        "outputId": "9737d914-c0c9-45d2-d5bd-1de840605dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Language', 'modeling', 'is'),\n",
              " ('modeling', 'is', 'the'),\n",
              " ('is', 'the', 'way'),\n",
              " ('the', 'way', 'of'),\n",
              " ('way', 'of', 'determining'),\n",
              " ('of', 'determining', 'the'),\n",
              " ('determining', 'the', 'probability'),\n",
              " ('the', 'probability', 'of'),\n",
              " ('probability', 'of', 'any'),\n",
              " ('of', 'any', 'sequence'),\n",
              " ('any', 'sequence', 'of'),\n",
              " ('sequence', 'of', 'words.')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's perform the ngrams take n=any value\n",
        "n=6\n",
        "six_grams = list(ngrams(text.split(),n))\n",
        "six_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeCEX2N-JOsr",
        "outputId": "de88a2bf-9ee6-42f6-9ec4-544a6af18a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Language', 'modeling', 'is', 'the', 'way', 'of'),\n",
              " ('modeling', 'is', 'the', 'way', 'of', 'determining'),\n",
              " ('is', 'the', 'way', 'of', 'determining', 'the'),\n",
              " ('the', 'way', 'of', 'determining', 'the', 'probability'),\n",
              " ('way', 'of', 'determining', 'the', 'probability', 'of'),\n",
              " ('of', 'determining', 'the', 'probability', 'of', 'any'),\n",
              " ('determining', 'the', 'probability', 'of', 'any', 'sequence'),\n",
              " ('the', 'probability', 'of', 'any', 'sequence', 'of'),\n",
              " ('probability', 'of', 'any', 'sequence', 'of', 'words.')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "# Preprocess the corpus\n",
        "def preprocess(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "def generate_bigrams(text):\n",
        "  return list(bigrams(text.split()))\n",
        "\n",
        "# Build the bigram model\n",
        "def build_bigram_model(bigrams):\n",
        "    model = defaultdict(Counter)\n",
        "    for w1, w2 in bigrams:\n",
        "        model[w1][w2] += 1\n",
        "    return model\n",
        "\n",
        "# Predict the next word\n",
        "def predict_next_word(model, word):\n",
        "    if word in model:\n",
        "        return model[word].most_common(1)[0][0]\n",
        "    else:\n",
        "        return random.choice(list(model.keys()))\n",
        "\n",
        "# Example usage\n",
        "bigrams = generate_bigrams(text)\n",
        "model = build_bigram_model(bigrams)\n",
        "\n",
        "# Predict the next word after \"Python\"\n",
        "next_word = predict_next_word(model, \"Language\")\n",
        "print(f\"The next word after 'Language' might be: {next_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rycTFg2AP6Eq",
        "outputId": "84ea6a07-1b22-4d7e-d01e-cd6b928557a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The next word after 'Language' might be: modeling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def laplace_smoothing(text):\n",
        "    # Preprocess and tokenize\n",
        "    text = text.lower().split()\n",
        "\n",
        "    # Generate bigrams\n",
        "    bigrams = [(text[i], text[i + 1]) for i in range(len(text) - 1)]\n",
        "\n",
        "    # Count bigrams and unigrams\n",
        "    bigram_counts = Counter(bigrams)\n",
        "    unigram_counts = Counter(text)\n",
        "\n",
        "    # Vocabulary size\n",
        "    vocab_size = len(set(text))\n",
        "\n",
        "    def get_smoothed_probability(w1, w2):\n",
        "        bigram_count = bigram_counts[(w1, w2)] + 1\n",
        "        unigram_count = unigram_counts[w1]\n",
        "        return bigram_count / (unigram_count + vocab_size)\n",
        "\n",
        "    return get_smoothed_probability\n",
        "\n",
        "# Example usage\n",
        "smoothed_prob = laplace_smoothing(text)\n",
        "\n",
        "# Example bigram probability\n",
        "print(f\"Probability of ('Language', 'modeling'): {smoothed_prob('Language', 'modeling'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1S-Fak6WmOa",
        "outputId": "75269755-563e-47ba-d0e5-9eacefeb34ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of ('Language', 'modeling'): 0.0909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tg3ebfV-aMbF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}