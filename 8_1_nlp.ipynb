{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg6WGIGp/0pROfJunni56W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darshnkd/NLP-labs/blob/main/8_1_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Name : Darshan Dhanwdae**\n",
        "\n",
        "**Roll No:24**"
      ],
      "metadata": {
        "id": "b-L6-SCwSRDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PRACTICAL : 08\n",
        "\n",
        "**AIM**: Perform the text summarization in NLP.\n",
        "\n",
        "```There are two main approches of text summarization.```\n",
        "\n",
        "* **1. Extractive Summarization :**\n",
        "\n",
        " This approach involves selecting and extracting segments (phrases, sentences, or paragraphs) directly from the original text to create a summary. The goal is to pull out the most important information verbatim.\n",
        "\n",
        "* **2. Abstractive Summarization:**\n",
        "\n",
        " This approach involves generating a summary that paraphrases or rewrites the original text, aiming to produce a more coherent and human-like summary."
      ],
      "metadata": {
        "id": "N7L8KWuTSgDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Extractive Summarization**"
      ],
      "metadata": {
        "id": "TNFyMrROSLwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK2m_JizPzlr",
        "outputId": "5801218d-8e1f-433b-cad6-d61b92b2d5b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "CZTqAAIAWwBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6__44jwWmIM",
        "outputId": "26bc35ac-ebc9-4043-e432-863fe85112a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sumy in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.32.3)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.10/dist-packages (from sumy) (24.6.1)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"In recent years, the rise of artificial intelligence (AI) has significantly transformed various sectors, including healthcare, finance, and education. AI technologies, such as machine learning and natural language processing, are being leveraged to improve efficiency, accuracy, and overall performance in these industries. For instance, in healthcare, AI-driven diagnostic tools are helping doctors to identify diseases earlier and more accurately, leading to better patient outcomes.\n",
        "\n",
        "In finance, AI algorithms are being used for predictive analytics, fraud detection, and personalized financial advice. These tools analyze vast amounts of data to make informed predictions and decisions, which can help in mitigating risks and optimizing investment strategies. Similarly, in education, AI-powered platforms are providing personalized learning experiences, automating administrative tasks, and supporting educators with valuable insights into student performance.\n",
        "\n",
        "Despite the numerous benefits of AI, there are also challenges and ethical considerations that need to be addressed. Issues such as data privacy, algorithmic bias, and the potential for job displacement are significant concerns that must be managed responsibly. Ensuring that AI systems are transparent, fair, and used ethically is crucial for gaining public trust and achieving positive societal impacts.\n",
        "\n",
        "Looking forward, the continued advancement of AI technologies holds the promise of further innovations and improvements. Researchers and practitioners are working towards creating more robust, adaptable, and ethical AI systems that can address complex problems and contribute to societal well-being. As AI continues to evolve, its integration into various domains will likely bring about transformative changes and new opportunities.\"\"\""
      ],
      "metadata": {
        "id": "SWJ6XHKMc3ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_summary(text, num_sentences=3):\n",
        "    # preprocess the text with spacy\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "    # Create PlaintextParser object\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "    # Initilize the TextRank summarizer\n",
        "    summarizer = TextRankSummarizer()\n",
        "\n",
        "    # generate summary\n",
        "    summary = summarizer(parser.document, num_sentences)\n",
        "\n",
        "    # Return the summary as string\n",
        "    return ' '.join([str(sentence) for sentence in summary])\n",
        "\n",
        "# print summary\n",
        "extract_summary(text)"
      ],
      "metadata": {
        "id": "5KcRRyKqbVOD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ce6d2117-4291-4e62-dbe9-90497dd29062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AI technologies, such as machine learning and natural language processing, are being leveraged to improve efficiency, accuracy, and overall performance in these industries. Ensuring that AI systems are transparent, fair, and used ethically is crucial for gaining public trust and achieving positive societal impacts. Researchers and practitioners are working towards creating more robust, adaptable, and ethical AI systems that can address complex problems and contribute to societal well-being.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "h--c5ct6fl85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd35b63-5b8d-441e-c950-4d4d930c17dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the summarization pipeline with BART\n",
        "summarizer = pipeline(\"summarization\") #model=\"facebook/bart-large-cnn\"\n",
        "\n",
        "def abstractive_summary(text, max_length=150, min_length=30):\n",
        "    # Generate the summary\n",
        "    summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=True)\n",
        "\n",
        "    # Return the summary text\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "print(abstractive_summary(text))\n",
        "\n",
        "\n",
        "## the warning in the output saying\n",
        "## The warning implies that you are using a summarization pipeline without specifying a model, so it's using a default model\n",
        "## which may not be ideal for your needs. To solve this, specify a model explicitly when creating the pipeline:"
      ],
      "metadata": {
        "id": "0aiNs4zsfmlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2006317-5eb9-4aa2-ca37-9805f55d655f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " In recent years, the rise of artificial intelligence has significantly transformed various sectors, including healthcare, finance, and education . AI technologies, such as machine learning and natural language processing, are being leveraged to improve efficiency, accuracy, and overall performance in these industries .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GkkCb5-2XpNm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}